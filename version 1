import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import SGDClassifier
from sklearn.model_selection import KFold

#read
X_full=pd.read_csv('../input/titanic/train.csv')
X_test_full=pd.read_csv('../input/titanic/test.csv')

#creating X and y
X_full.dropna(axis=0, subset=['Survived'], inplace=True)
y = X_full.Survived
X_full.drop(['Survived'], axis=1, inplace=True)

#Drop useless columns
X_full.drop(['Cabin','Ticket','Name','Embarked','PassengerId'],axis=1, inplace=True)
X_test_full.drop(['Cabin','Ticket','Name','Embarked'],axis=1, inplace=True)

#Missing values
missing_val_count_by_column = (X_full.isnull().sum())
missing_val_count_by_column_test = (X_test_full.isnull().sum())
print('Number of missing values per columns in training Dataset:')
print(missing_val_count_by_column[missing_val_count_by_column > 0])
print('Number of missing values per columns in test Dataset:')
print(missing_val_count_by_column_test[missing_val_count_by_column_test > 0])



#train test split, categorical and numerical columns
X_train_full,X_valid_full,y_train,y_valid=train_test_split(X_full,y,
                                                           train_size=0.8,test_size=0.2,
                                                           random_state=0)


categorical_cols=[cname for cname in X_train_full.columns 
                  if X_train_full[cname].dtype=='object']


numerical_cols=[nname for nname in X_train_full.columns 
                if X_train_full[nname].dtype in ['int64','Float64']]

cols=numerical_cols+categorical_cols

X_train=X_train_full[cols].copy()
X_valid=X_valid_full[cols].copy()
X_test=X_test_full.copy()

#prepocessing the data
numerical_pipeline=make_pipeline(SimpleImputer())
categorical_pipeline=make_pipeline(SimpleImputer(strategy='most_frequent'),
                                   OneHotEncoder(handle_unknown='ignore'))
preprocessor=make_column_transformer((numerical_pipeline, numerical_cols),
                                     (categorical_pipeline, categorical_cols))
                                     
                                     
#defining the model                                     
Forest = RandomForestRegressor(n_estimators=100, random_state=0)


#training
model=make_pipeline(preprocessor,Forest)
model.fit(X_train,y_train)

#cross validation
k_fold = KFold(n_splits=5, shuffle=True, random_state=0)
def acc_score(model):
    return np.mean(cross_val_score(model,X_train,y_train,cv=k_fold,scoring="accuracy"))
    
#prediction
preds_test = model.predict(X_test)
preds_test_list=list(preds_test)
round_preds_test_list=[round(num,0) for num in preds_test_list]
int_round_preds_test_list=[int(num)for num in round_preds_test_list]

#export to csv
output = pd.DataFrame({'PassengerId': X_test.PassengerId,
                       'Survived': int_round_preds_test_list})
output.to_csv('submission.csv', index=False)
